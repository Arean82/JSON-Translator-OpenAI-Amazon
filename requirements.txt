# =============================================
# Core AI/ML Dependencies
# =============================================

# PyTorch (choose based on your hardware)
torch>=2.0.1
# For CUDA (NVIDIA GPU) - uncomment one of these:
# torch>=2.0.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117
# torch>=2.0.1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118

# Transformers and Hugging Face ecosystem
transformers>=4.34.0
accelerate>=0.23.0
sentencepiece>=0.1.99
protobuf>=3.20.0
tokenizers>=0.14.0
huggingface-hub>=0.17.0

# Model quantization (reduces memory usage)
bitsandbytes>=0.41.0

# Progress bars for downloads
tqdm>=4.65.0

# =============================================
# Cloud Translation Engines
# =============================================

# OpenAI API
openai>=1.3.0

# AWS Translate
boto3>=1.28.0

# =============================================
# GUI Dependencies
# =============================================

# Tkinter (usually comes with Python)
# If needed on Linux: python3-tk

# Enhanced GUI components
pillow>=10.0.0

# =============================================
# Utilities
# =============================================

# HTTP requests
requests>=2.31.0

# System monitoring
psutil>=5.9.0

# JSON handling
ujson>=5.7.0  # Faster JSON processing

# File type detection
filetype>=1.2.0

# =============================================
# Optional: Performance Optimizations
# =============================================

# Faster model loading
safetensors>=0.3.3

# Optional: Flash Attention (faster inference)
# flash-attn>=2.3.0  # Note: Requires specific CUDA versions

# Optional: For better tokenization
regex>=2023.6.3

callable
